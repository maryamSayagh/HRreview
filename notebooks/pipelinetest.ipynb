{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:19:05.803140Z",
     "start_time": "2025-08-24T08:18:55.513686Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7da681320972563c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:48:40.026441Z",
     "start_time": "2025-08-24T08:48:40.021408Z"
    }
   },
   "cell_type": "code",
   "source": [
    " lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"query\", \"value\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\"\n",
    "    )"
   ],
   "id": "e4f9698baa5c421",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-24T08:49:10.192406Z",
     "start_time": "2025-08-24T08:49:01.819187Z"
    }
   },
   "source": [
    "\n",
    "# --- Step 1: Load and Embed with T5 (Semantic Search) ---\n",
    "def embed_with_t5(texts, model_name=\"t5-base\"):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5EncoderModel.from_pretrained(model_name)\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# --- Step 2: Classify with SciBERT + LoRA ---\n",
    "def classify_with_scibert_lora(texts, labels, model_name=\"allenai/scibert_scivocab_uncased\",lora_config=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)  # P, I, C, O\n",
    "\n",
    "    # LoRA Config\n",
    "\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    # Tokenize and prepare dataset\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # Fine-tune or use pre-trained LoRA weights here\n",
    "    # (For demo, we skip training and assume model is already fine-tuned)\n",
    "    # Trainer API can be used for actual fine-tuning\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return preds.numpy()\n",
    "\n",
    "# --- Step 3: Downstream Tasks ---\n",
    "def sentiment_analysis(texts):\n",
    "    # Use twitter-roberta-base-sentiment\n",
    "    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    return torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "def ner_extraction(texts):\n",
    "    # Use a NER model like dslim/bert-base-NER\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    # Post-process to extract entities\n",
    "    # (Simplified for demo)\n",
    "    return [\"Participant1\", \"Participant2\"]  # Placeholder\n",
    "\n",
    "# --- Main Pipeline ---\n",
    "def process_paper(title, abstract, text):\n",
    "    # Combine all text\n",
    "    all_texts = [title, abstract, text]\n",
    "\n",
    "    # Step 1: Embed with T5\n",
    "    embeddings = embed_with_t5(all_texts)\n",
    "\n",
    "    # Step 2: Classify with SciBERT + LoRA\n",
    "    # (Assuming you have labels for demo, replace with actual labels)\n",
    "    labels = [0, 1, 2, 3]  # Dummy labels\n",
    "    pico_labels = classify_with_scibert_lora(all_texts, labels)\n",
    "\n",
    "    # Step 3: Downstream tasks\n",
    "    sentiment = sentiment_analysis([t for i, t in enumerate(all_texts) if pico_labels[i] == 1])  # I/O only\n",
    "    participants = ner_extraction([t for i, t in enumerate(all_texts) if pico_labels[i] == 0])  # P only\n",
    "\n",
    "    return {\n",
    "        \"embeddings\": embeddings,\n",
    "        \"pico_labels\": pico_labels,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"participants\": participants\n",
    "    }\n",
    "\n",
    "# --- Example Usage ---\n",
    "title = \"Effect of X on Y: A Randomized Trial\"\n",
    "abstract = \"This study investigates the effect of X on Y in patients with Z...\"\n",
    "text = \"Methods: We randomized 100 patients to X or placebo...\"\n",
    "result = process_paper(title, abstract, text)\n",
    "print(result)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 442.22 MB. The target location C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--allenai--scibert_scivocab_uncased\\blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "408ca82ad89147fb9e197796743f63d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Can't load the model for 'allenai/scibert_scivocab_uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'allenai/scibert_scivocab_uncased' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\modeling_utils.py:1208\u001B[39m, in \u001B[36m_get_resolved_checkpoint_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001B[39m\n\u001B[32m   1207\u001B[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001B[32m-> \u001B[39m\u001B[32m1208\u001B[39m         resolved_archive_file = \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1209\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcached_file_kwargs\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1211\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001B[32m   1212\u001B[39m     \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\utils\\hub.py:321\u001B[39m, in \u001B[36mcached_file\u001B[39m\u001B[34m(path_or_repo_id, filename, **kwargs)\u001B[39m\n\u001B[32m    268\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    269\u001B[39m \u001B[33;03mTries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001B[39;00m\n\u001B[32m    270\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    319\u001B[39m \u001B[33;03m```\u001B[39;00m\n\u001B[32m    320\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m321\u001B[39m file = \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    322\u001B[39m file = file[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\utils\\hub.py:567\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    566\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, EntryNotFoundError):\n\u001B[32m--> \u001B[39m\u001B[32m567\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    569\u001B[39m resolved_files = [\n\u001B[32m    570\u001B[39m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m full_filenames\n\u001B[32m    571\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\utils\\hub.py:479\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    477\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(full_filenames) == \u001B[32m1\u001B[39m:\n\u001B[32m    478\u001B[39m     \u001B[38;5;66;03m# This is slightly better for only 1 file\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m     \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    487\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:1010\u001B[39m, in \u001B[36mhf_hub_download\u001B[39m\u001B[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[39m\n\u001B[32m   1009\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1010\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1011\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[32m   1012\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1013\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[32m   1014\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1015\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1017\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1018\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[32m   1019\u001B[39m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1020\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1021\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1022\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1023\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1024\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[32m   1025\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:1171\u001B[39m, in \u001B[36m_hf_hub_download_to_cache_dir\u001B[39m\u001B[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[39m\n\u001B[32m   1170\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m WeakFileLock(lock_path):\n\u001B[32m-> \u001B[39m\u001B[32m1171\u001B[39m     \u001B[43m_download_to_tmp_and_move\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.incomplete\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1173\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1174\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1180\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1181\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1183\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(pointer_path):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:1723\u001B[39m, in \u001B[36m_download_to_tmp_and_move\u001B[39m\u001B[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001B[39m\n\u001B[32m   1722\u001B[39m     logger.debug(\u001B[33m\"\u001B[39m\u001B[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1723\u001B[39m     \u001B[43mxet_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1724\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1725\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1726\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1727\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1728\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisplayed_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1729\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1730\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:629\u001B[39m, in \u001B[36mxet_get\u001B[39m\u001B[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001B[39m\n\u001B[32m    627\u001B[39m     progress.update(progress_bytes)\n\u001B[32m--> \u001B[39m\u001B[32m629\u001B[39m \u001B[43mdownload_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    630\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxet_download_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    631\u001B[39m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    632\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_info\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43maccess_token\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnection_info\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexpiration_unix_epoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    633\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken_refresher\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken_refresher\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    634\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprogress_updater\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mprogress_updater\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    635\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Data processing error: CAS service error : IO Error: There is not enough space on the disk. (os error 112)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 83\u001B[39m\n\u001B[32m     81\u001B[39m abstract = \u001B[33m\"\u001B[39m\u001B[33mThis study investigates the effect of X on Y in patients with Z...\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     82\u001B[39m text = \u001B[33m\"\u001B[39m\u001B[33mMethods: We randomized 100 patients to X or placebo...\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m result = \u001B[43mprocess_paper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtitle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabstract\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[38;5;28mprint\u001B[39m(result)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 66\u001B[39m, in \u001B[36mprocess_paper\u001B[39m\u001B[34m(title, abstract, text)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# Step 2: Classify with SciBERT + LoRA\u001B[39;00m\n\u001B[32m     64\u001B[39m \u001B[38;5;66;03m# (Assuming you have labels for demo, replace with actual labels)\u001B[39;00m\n\u001B[32m     65\u001B[39m labels = [\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m, \u001B[32m3\u001B[39m]  \u001B[38;5;66;03m# Dummy labels\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m pico_labels = \u001B[43mclassify_with_scibert_lora\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[38;5;66;03m# Step 3: Downstream tasks\u001B[39;00m\n\u001B[32m     69\u001B[39m sentiment = sentiment_analysis([t \u001B[38;5;28;01mfor\u001B[39;00m i, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(all_texts) \u001B[38;5;28;01mif\u001B[39;00m pico_labels[i] == \u001B[32m1\u001B[39m])  \u001B[38;5;66;03m# I/O only\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 13\u001B[39m, in \u001B[36mclassify_with_scibert_lora\u001B[39m\u001B[34m(texts, labels, model_name, lora_config)\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mclassify_with_scibert_lora\u001B[39m(texts, labels, model_name=\u001B[33m\"\u001B[39m\u001B[33mallenai/scibert_scivocab_uncased\u001B[39m\u001B[33m\"\u001B[39m,lora_config=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m     12\u001B[39m     tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     model = \u001B[43mAutoModelForSequenceClassification\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_labels\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m4\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# P, I, C, O\u001B[39;00m\n\u001B[32m     15\u001B[39m     \u001B[38;5;66;03m# LoRA Config\u001B[39;00m\n\u001B[32m     17\u001B[39m     model = get_peft_model(model, lora_config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    598\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    599\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    601\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    602\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    603\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    604\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    605\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    606\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\modeling_utils.py:317\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    315\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    316\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m317\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    319\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\modeling_utils.py:4923\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4913\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   4914\u001B[39m     gguf_file\n\u001B[32m   4915\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4916\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m ((\u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map.values()) \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map)\n\u001B[32m   4917\u001B[39m ):\n\u001B[32m   4918\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   4919\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4920\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mloaded from GGUF files.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4921\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m4923\u001B[39m checkpoint_files, sharded_metadata = \u001B[43m_get_resolved_checkpoint_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4924\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4925\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4926\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4927\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4928\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4929\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4930\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4931\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4932\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4933\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4934\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4935\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4936\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4937\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4938\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4939\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_auto_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4940\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtransformers_explicit_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransformers_explicit_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4941\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4943\u001B[39m is_sharded = sharded_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4944\u001B[39m is_quantized = hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\modeling_utils.py:1297\u001B[39m, in \u001B[36m_get_resolved_checkpoint_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001B[39m\n\u001B[32m   1294\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m   1295\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1296\u001B[39m         \u001B[38;5;66;03m# For any other exception, we throw a generic error.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1297\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[32m   1298\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt load the model for \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m. If you were trying to load it\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1299\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m from \u001B[39m\u001B[33m'\u001B[39m\u001B[33mhttps://huggingface.co/models\u001B[39m\u001B[33m'\u001B[39m\u001B[33m, make sure you don\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt have a local directory with the\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1300\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m same name. Otherwise, make sure \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m is the correct path to a\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1301\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m directory containing a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1302\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF2_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m or \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mFLAX_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1303\u001B[39m         ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m   1305\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_local:\n\u001B[32m   1306\u001B[39m     logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mloading weights file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchive_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mOSError\u001B[39m: Can't load the model for 'allenai/scibert_scivocab_uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'allenai/scibert_scivocab_uncased' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "arxiv=pd.read_csv(\"C://Users//Lenovo//PycharmProjects//HRreview//review//data//papers_sample.csv\")",
   "id": "b3a27ab3c1ef523",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f6678bdab27ea08",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
