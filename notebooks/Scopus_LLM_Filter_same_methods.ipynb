{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f40226b",
   "metadata": {},
   "source": [
    "\n",
    "# Scopus Journal Filtering (Same Methods)\n",
    "\n",
    "This notebook mirrors your original workflow and relies **only** on your LLM-based filter:\n",
    "- `os.chdir(\"/content/HRreview/review\")`\n",
    "- `pd.read_csv(..., encoding=\"latin-1\")` then `replace(\"NaN\", np.nan, inplace=True)`\n",
    "- Drops **Coverage** and **Article Language** from the **working copy** *before* LLM filtering\n",
    "- Uses `column_name = ['Source Title']`\n",
    "- Builds `context` from `about.txt` plus your keyword list\n",
    "- Imports `journal_filter_gpt` from your Scripts folder\n",
    "- Calls `journal_filter_gpt.filter_journal_dataframe(df, client, column_name, context, \"list\", 45)`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb7562b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T19:36:28.435412Z",
     "start_time": "2025-08-12T19:36:28.195299Z"
    }
   },
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scopus = pd.read_csv(\"review/data/Journals/Scopus/ext_list_Jul_2025_Scopus_Sources_Jul.csv\")\n",
    "print(f\"Loaded {len(scopus)} rows\")\n",
    "scopus.head(2)\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'review/data/Journals/Scopus/ext_list_Jul_2025_Scopus_Sources_Jul.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m scopus = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreview/data/Journals/Scopus/ext_list_Jul_2025_Scopus_Sources_Jul.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mLoaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(scopus)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m rows\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     10\u001B[39m scopus.head(\u001B[32m2\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'review/data/Journals/Scopus/ext_list_Jul_2025_Scopus_Sources_Jul.csv'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101804f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove date and language columns *from the working copy* before LLM filtering\n",
    "WORKING_DROP_COLS = [\n",
    "    'Article Language in Source (Three-Letter ISO Language Codes)',\n",
    "    'Coverage',\n",
    "]\n",
    "\n",
    "scopus_work = scopus.copy()\n",
    "for col in WORKING_DROP_COLS:\n",
    "    if col in scopus_work.columns:\n",
    "        scopus_work.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Keep the exact column name you used\n",
    "column_name = ['Source Title']\n",
    "\n",
    "# Prepare the minimal frame to send to LLM\n",
    "scopus_for_llm = scopus_work[column_name].dropna().drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Unique titles sent to LLM: {len(scopus_for_llm)}\")\n",
    "scopus_for_llm.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144eeb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your utility to read context\n",
    "def read_txt(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Build context exactly like your snippet\n",
    "context = read_txt(\"../../../Downloads/about.txt\")\n",
    "context = context + \"\"\"these are keywords refering to the subject we are studying :[Human in the loop\",\n",
    "        \"AI-human interaction\",\n",
    "        \"Decision Making\",\n",
    "        \"AI recommendation\"\n",
    "        ,\"Trust in recommendation\",\n",
    "        \"Explanable Artificial inteligence\",\n",
    "        'Artificial intelligence Bias',\n",
    "        'Operational Analytics Decision',\n",
    "        'AI assisted decision making',\n",
    "        'Trust in automation',\n",
    "        'Automation bias',\n",
    "        'Human-AI Collaboration',\n",
    "        'HAIC Evaluation']\"\"\"\n",
    "print(\"Context prepared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a589d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import your LLM filter and OpenAI client, preserving your style\n",
    "import sys\n",
    "sys.path.append('/content/HRreview/review/Scripts')\n",
    "\n",
    "import journal_filter_gpt\n",
    "\n",
    "# OpenAI client initialization like your pattern\n",
    "from openai import OpenAI\n",
    "try:\n",
    "    import userdata  # if present in your environment\n",
    "    gpt = userdata.get('OPENAI_API_KEY')\n",
    "except Exception:\n",
    "    gpt = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "if not gpt:\n",
    "    raise ValueError(\"OpenAI API key not found. Set via userdata.get('OPENAI_API_KEY') or env var OPENAI_API_KEY.\")\n",
    "\n",
    "client = OpenAI(api_key=gpt)\n",
    "print(\"OpenAI client initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Call your LLM-based journal filter EXACTLY like your snippet\n",
    "f = journal_filter_gpt.filter_journal_dataframe(\n",
    "    scopus_for_llm,\n",
    "    client,\n",
    "    column_name,\n",
    "    context ,\n",
    "    \"list\",  # can be \"dict\" or \"list\"\n",
    "    45\n",
    ")\n",
    "\n",
    "type(f), (len(f) if isinstance(f, list) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d7a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize possible returns (list/dict/DataFrame) but keep logic minimal\n",
    "if isinstance(f, list):\n",
    "    accepted_titles = set(map(str, f))\n",
    "elif isinstance(f, dict):\n",
    "    # Try common keys; if your function returns dict, adjust here if needed\n",
    "    for k in (\"keep\", \"accepted\", \"titles\", \"result\"):\n",
    "        if k in f and isinstance(f[k], (list, set, tuple)):\n",
    "            accepted_titles = set(map(str, f[k]))\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected dict structure from LLM filter. Please return a list of titles.\")\n",
    "elif isinstance(f, pd.DataFrame) and 'Source Title' in f.columns:\n",
    "    accepted_titles = set(map(str, f['Source Title'].dropna().unique().tolist()))\n",
    "else:\n",
    "    raise TypeError(\"Unexpected return type from LLM filter. Expected list/dict/DataFrame with 'Source Title'.\")\n",
    "\n",
    "print(f\"Accepted titles: {len(accepted_titles)}\")\n",
    "list(sorted(list(accepted_titles))[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the original scopus DataFrame by accepted titles and save\n",
    "scopus_filtered = scopus[scopus['Source Title'].astype(str).isin(accepted_titles)].copy()\n",
    "scopus_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "out_path = \"data/Journals/Scopus/Scopus_list_sources_llm_filtered.csv\"\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "scopus_filtered.to_csv(out_path, index=False)\n",
    "print(f\"Saved filtered journals to: {out_path} (rows: {len(scopus_filtered)})\")\n",
    "scopus_filtered.head(5)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
